---
title: "TMA4285 Ex3"
author: "Marius Dioli"
date: "September 9, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	error = FALSE,
	message = FALSE,
	warning = FALSE,
	include = FALSE,
	results = "hold"
)
knitr::opts_chunk$set(error=TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(results="hold")

```


```{r}
#Imports
library("knitr") #probably already installed
library("rmarkdown") #probably already installed
library(astsa)
```

# Minimum

1. Exploring the data with plotting of relevant statistics
2. Transforming the data
3. Model parameter estimation including uncertainty
4. Diagnostics, and model choice discussion


# Abstract


# Introduction



# Theory

Outline theory. Start by discussing types of data and behaviour of data. Then talk about modelling and assumptions. Onto MA and AR, then ARMA, then ARIMA processes. Estimation and such

# Data Analysis
```{r}
#Load data
path = "mlo_data/"
marius_path = "C:/Users/mariu/Documents/Time-Series/mlo_data/"
daily_c13iso = read.csv(paste(marius_path, "daily_flask_c13_mlo.csv", sep=""), na.strings=-99.99)
monthly_c13iso = read.csv(paste(marius_path, "monthly_flask_c13_mlo.csv", sep=""), na.strings=-99.99)
daily_o18iso = read.csv(paste(marius_path, "daily_flask_o18_mlo.csv", sep=""), na.strings=-99.99)
intermittent_c13iso = read.csv(paste(marius_path, "intermittent_flask_c14_mlo.csv", sep=""), na.strings=-99.99)
monthly_o18iso = read.csv(paste(marius_path, "monthly_flask_o18_mlo.csv", sep=""), na.strings=-99.99)
daily_flask = read.csv(paste(marius_path, "daily_flask_co2_mlo.csv", sep=""), na.strings=-99.99)
monthly_flask = read.csv(paste(marius_path, "monthly_flask_co2_mlo.csv", sep=""), na.strings=-99.99)
ten_min_insitu = read.csv(paste(marius_path, "ten_minute_in_situ_co2_mlo.txt", sep=""), na.strings=-99.99)
daily_insitu = read.csv(paste(marius_path, "daily_in_situ_co2_mlo.csv", sep=""), comment.char = '%', na.strings=-99.99)
weekly_insitu = read.csv(paste(marius_path, "weekly_in_situ_co2_mlo.csv", sep=""), na.strings=-99.99)
monthly_insitu = read.csv(paste(marius_path, "monthly_in_situ_co2_mlo.csv", sep=""), na.strings=-99.99)


#fixes headers
names(intermittent_c13iso) = c("Date", "C13")
names(monthly_flask) = c( "Yr", "Mn", "Date1", "Date2", "CO2","seasonally", "fit",  "seasonally2", "CO2_filled", "seasonally3")
names(monthly_insitu) = c( "Yr", "Mn", "Date1", "Date2", "CO2","seasonally", "fit",  "seasonally2", "CO2_filled", "seasonally3")
names(monthly_c13iso) = c( "Yr", "Mn", "Date1", "Date2", "C13","seasonally", "fit",  "seasonally2", "C13_filled", "seasonally3")
names(monthly_o18iso) = c( "Yr", "Mn", "Date1", "Date2", "O18","seasonally", "fit",  "seasonally2", "O18_filled", "seasonally3")
names(weekly_insitu) = c("Date", "CO2")
names(daily_flask) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "CO2")
names(daily_insitu) = c("Yr", "Mn", "Dy", "CO2", "NB", "Scale")
names(daily_c13iso) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "C13")
names(daily_o18iso) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "O18")
names(ten_min_insitu) = c('Yr','Mn','Dy','Hr','Mi', 'CO2')




#Splitting into two dataframes so that we can delete the NA rows in the non-filled-in data
monthly_flask1 = monthly_flask
monthly_flask1[9:10] = list(NULL) 

monthly_flask2 = monthly_flask
monthly_flask2[5:8] = list(NULL) 
na.omit(monthly_flask1)
```
We start by creating simple time series plot to get an overview. 
```{r}
#Creating basic plots
plot(data.frame(monthly_flask2$Date2, monthly_flask2$CO2_filled), type="o", ylab="CO2 Levels")
plot(data.frame(monthly_flask1$Date2, monthly_flask1$CO2), type="o", ylab="CO2 Levels")
plot.ts(monthly_flask2$CO2_filled, type='s')

#Converting to timeseries
ts = as.ts(monthly_flask2$CO2_filled, deltat = 1/12)
'?'(ts)
ts = ts[-1]
acf(ts, 100, main='Monthly CO2 flask reading')

#Definitely not stationary, apply differencing. The book states that differencing is a more robust method than decomposition
plot(diff(ts, 12), type='o', main='first difference')
acf(diff(ts, 12), 100, main='Monthly CO2 flask reading')

#Nope, we should apply two times differncing

plot(diff(diff(ts, 12)), type='o', main='Second difference')
acf(diff(diff(ts, 12)),100, main='Monthly CO2 flask reading')

# Seems to be some regular trends, after a few months there are tops in the acf. # maybe there is some seasonal variance repeating each 12 months
plot(diff(ts, 12), type='o', main='Second difference')
acf(diff(ts, 12), length(monthly_flask2$CO2_filled), main='Monthly CO2 flask reading')

## Seems better, but still is some acf frome earlier months, following the 
## Sarima way of thinking we can difference some more until it get better
plot(diff(diff(ts, 12),1), type='o', main='Second difference')
acf(diff(diff(ts, 12),1), main='Monthly CO2 flask reading')
pacf(diff(diff(ts, 12),1), main='Monthly CO2 flask reading')

#Based on the fact that both the acf and pacf function tail off, we conclude that an arma style model fits best, in this case a sarima model.

## The autocorrlation now seems ok, we will not make our model to complex, so we ## decide on using the selected values. 
```

Now plotting the transformed data we get:
```{r}
ts.transformed <- diff(diff(ts, 12),2)
plot(ts.transformed, type = 'o')
```
Which seems like a stationary process.  

So we decide on using  $\nabla\nabla^{12}$ as our tranformation. 

Which results in a SARIMA model. As for instance:
```{r}
sarima(ts, p=1, d=2, q=1, P=1, Q=1, D=2, S=12)
#test

```
(Coefficient can i.e. be fit using innovations algoritihm. But that might not be the method impletemented in the package).
To find the best choice of parameters we compare AIC and AICC of different models. 

```{r}
optimal_sarima = function(timeseries){
minVal.AIC <- c(10000,1,1,1,1)
minVal.AICC <- c(10000,1,1,1,1)
minVal.BIC <- c(10000,1,1,1,1)
errorAt <- c()
for(p1 in 4:5){
  for(q1 in 1:5){
    for(P1 in 1:5){
      for(Q1 in 1:5){
        mod <- tryCatch(sarima(ts, p=p1, d=2, q=q1, P=P1, D=2, S=12, Q = Q1, no.constant = T, tol = 1e-3),
                 error = function(e) "ERROR")
        if(mod == "ERROR"){
          errorAt <- append(errorAt, c(p1, q1, P1, Q1))
          next
        }
        if(mod$AIC < minVal.AIC[1]){
          minVal.AIC <- c(mod$AIC, p1, q1, P1, Q1)
        }
        if(mod$AICc < minVal.AICC[1]){
          minVal.AICC <- c(mod$AICc, p1, q1, P1, Q1)
        }
        if(mod$BIC < minVal.BIC[1]){
          minVal.BIC <- c(mod$BIC, p1, q1, P1, Q1)
        }
        
      }
    }
  }
}
return(minVal.AICC)
}
# 4 1 5 1 seems to be best with 1.27 AIC and 1.27 AICC 
```

```{r}
mod <- sarima(ts, p=4, d=2, q=1, P=5, Q=1, D=2, S=12)
mod$ttable
```

```{r}
#Confidence intervals
#Since we have a large sample size we can use a normal approximation to calculate the confidence intervals to be the estimate plus/minus 
# their estimate/1.96*their standard deviation
ci = c()
for(i in 1:11){
  upper = mod$ttable[i, 1] + 1.96*mod$ttable[i, 2]
  lower = mod$ttable[i, 1] - 1.96*mod$ttable[i, 2]
  ci = rbind(ci, c(mod$ttable[i, 1], lower, upper))
}
ci = as.data.frame(ci)
names(ci) = c("Estimate", "Lower bound", "Upper bound")
ci

```


```{r}
#Predictions
fore = predict(mod$fit, n.ahead=300)
forecast = append(ts, fore$pred)
ts.plot(ts, xlim=c(0,1000), ylim=c(310, 500), ylab="Monthly CO2")
U = fore$pred+fore$se; L = fore$pred-fore$se 
xx = c(time(U), rev(time(U))); yy = c(L, rev(U)) 
polygon(xx, yy, border = 8, col = gray(.6, alpha =.2)) 
lines(fore$pred, col=2)
```

We see that the SARIMA generates a reasonable prediction.

Now let us explore the remaining data.
```{r}
#Monthly in situ

#Plots
ts_monthly_insitu = as.ts(na.omit(monthly_insitu$CO2_filled), deltat=1/12)
plot.ts(monthly_insitu$CO2_filled, type='s')
acf2(ts)
acf(ts)

#differencing
x = acf2(diff(ts, 12))
acf2(diff(diff(ts,12),1))

'?'(acf)
'?'(diff)

#Daily flask and insitu

ts_daily_flask = as.ts(na.omit(daily_flask$CO2), deltat=1/365)
ts_daily_insitu = as.ts(na.omit(daily_insitu$CO2), deltat=1/365)
plot.ts(ts_daily_flask, type='s')
plot.ts(ts_daily_insitu, type='s')

#Insitu lacks outliers
#Differencing and acf
acf2(ts_daily_flask)
acf2(ts_daily_insitu)

#First difference
acf2(diff(ts_daily_flask, 365))
acf2(diff(ts_daily_insitu, 365))


'?'(acf)
#Second difference
acf2(diff(diff(ts_daily_flask, 365)))
acf2(diff(diff(ts_daily_insitu, 365)))


#C13
plotter(as.ts(monthly_c13iso$C13_filled, deltat=1/12), 12)
plotter(as.ts(daily_c13iso$C13, deltat=1/365), 365)

#O18
plotter(as.ts(monthly_o18iso$O18, deltat=1/12), 12)
plotter(as.ts(daily_o18iso$O18, deltat=1/365), 365)

#Weekly
plotter(as.ts(weekly_insitu$CO2, deltat=1/52), 52)

#Ten minutes
plotter(as.ts(ten_min_insitu$CO2, deltat=1/525600), 525600)

#Intermittent
plotter(as.ts(intermittent_c13iso$C13, deltat=1/8), 8)



#test

```
We see that the data look broadly the same


```{r}
#Creating function that makes all the necessary plots
plotter = function(timeseries, first_diff){
  plot.ts(timeseries, type='s')
  acf2(timeseries)
  
  #First differencing
  plot.ts(diff(timeseries, first_diff), type='s')
  acf2(diff(timeseries, first_diff))
  
  #Second differencing
  plot.ts(diff(diff(timeseries)), type='s')
  acf2(diff(diff(timeseries)))
}
```


#Remaining
Plots with the different timeseries' predictions
Discussion
Clean up and prettify things, though probs not really necessary


# Discussion

We see from the analysis that none of the time series are stationary. However, ...
Talk about uncertainty, known unknowns, and unknown unknowns.

Weaknesses of chosen model and alternative models.

# Conclusion

# Appendix

# References

