---
title: "TMA4285 Ex3"
author: "Marius Dioli"
date: "September 9, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	error = FALSE,
	message = FALSE,
	warning = FALSE,
	include = FALSE,
	results = "hold"
)
knitr::opts_chunk$set(error=TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(results="hold")

```


```{r}
#Imports
library("knitr") #probably already installed
library("rmarkdown") #probably already installed
library(astsa)
```

# Minimum

1. Exploring the data with plotting of relevant statistics
2. Transforming the data
3. Model parameter estimation including uncertainty
4. Diagnostics, and model choice discussion


# Abstract


# Introduction



# Theory

Outline theory. Start by discussing types of data and behaviour of data. Then talk about modelling and assumptions. Onto MA and AR, then ARMA, then ARIMA processes. Estimation and such

# Data Analysis
```{r}
#Load data
path = "mlo_data/"
marius_path = "C:/Users/mariu/Documents/Time-Series/mlo_data/"
daily_c13iso = read.csv(paste(marius_path, "daily_flask_c13_mlo.csv", sep=""), na.strings=-99.99)
monthly_c13iso = read.csv(paste(marius_path, "monthly_flask_c13_mlo.csv", sep=""), na.strings=-99.99)
daily_o18iso = read.csv(paste(marius_path, "daily_flask_o18_mlo.csv", sep=""), na.strings=-99.99)
intermittent_c13iso = read.csv(paste(marius_path, "intermittent_flask_c14_mlo.csv", sep=""), na.strings=-99.99)
monthly_o18iso = read.csv(paste(marius_path, "monthly_flask_o18_mlo.csv", sep=""), na.strings=-99.99)
daily_flask = read.csv(paste(marius_path, "daily_flask_co2_mlo.csv", sep=""), na.strings=-99.99)
monthly_flask = read.csv(paste(marius_path, "monthly_flask_co2_mlo.csv", sep=""), na.strings=-99.99)
ten_min_insitu = read.csv(paste(marius_path, "ten_minute_in_situ_co2_mlo.txt", sep=""), na.strings=-99.99)
daily_insitu = read.csv(paste(marius_path, "daily_in_situ_co2_mlo.csv", sep=""), comment.char = '%', na.strings=-99.99)
weekly_insitu = read.csv(paste(marius_path, "weekly_in_situ_co2_mlo.csv", sep=""), na.strings=-99.99)
monthly_insitu = read.csv(paste(marius_path, "monthly_in_situ_co2_mlo.csv", sep=""), na.strings=-99.99)


#fixes headers
names(intermittent_c13iso) = c("Date", "C13")
names(monthly_flask) = c( "Yr", "Mn", "Date1", "Date2", "CO2","seasonally", "fit",  "seasonally2", "CO2_filled", "seasonally3")
names(monthly_insitu) = c( "Yr", "Mn", "Date1", "Date2", "CO2","seasonally", "fit",  "seasonally2", "CO2_filled", "seasonally3")
names(monthly_c13iso) = c( "Yr", "Mn", "Date1", "Date2", "C13","seasonally", "fit",  "seasonally2", "C13_filled", "seasonally3")
names(monthly_o18iso) = c( "Yr", "Mn", "Date1", "Date2", "O18","seasonally", "fit",  "seasonally2", "O18_filled", "seasonally3")
names(weekly_insitu) = c("Date", "CO2")
names(daily_flask) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "CO2")
names(daily_insitu) = c("Yr", "Mn", "Dy", "CO2", "NB", "Scale")
names(daily_c13iso) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "C13")
names(daily_o18iso) = c("Date1", "Date2", "Date3","Date4", "Number_of_flasks", "Flags", "O18")
names(ten_min_insitu) = c('Yr','Mn','Dy','Hr','Mi', 'CO2')




#Splitting into two dataframes so that we can delete the NA rows in the non-filled-in data
monthly_flask1 = monthly_flask
monthly_flask1[9:10] = list(NULL) 

monthly_flask2 = monthly_flask
monthly_flask2[5:8] = list(NULL) 
na.omit(monthly_flask1)
```
We start by creating simple time series plot to get an overview. 
```{r}
#Creating basic plots
plot(data.frame(monthly_flask2$Date2, monthly_flask2$CO2_filled), type="o", ylab="CO2 Levels")
plot(data.frame(monthly_flask1$Date2, monthly_flask1$CO2), type="o", ylab="CO2 Levels")
plot.ts(monthly_flask2$CO2_filled, type='s')

#Converting to timeseries
ts = as.ts(monthly_flask2$CO2_filled, deltat = 1/12)
'?'(ts)
ts = ts[-1]
acf(ts, 100, main='Monthly CO2 flask reading')

#Definitely not stationary, apply differencing. The book states that differencing is a more robust method than decomposition
plot(diff(ts, 12), type='o', main='first difference')
acf2(diff(ts, 12), 100, main='Monthly CO2 flask reading')

#Nope, we should apply two times differncing

plot(diff(diff(ts, 12)), type='o', main='Second difference')
acf2(diff(diff(ts, 12)), main='Monthly CO2 flask reading')


# Seems to be some regular trends, after a few months there are tops in the acf. # maybe there is some seasonal variance repeating each 12 months
plot(diff(ts, 12), type='o', main='Second difference')
acf(diff(ts, 12), length(monthly_flask2$CO2_filled), main='Monthly CO2 flask reading')

## Seems better, but still is some acf frome earlier months, following the 
## Sarima way of thinking we can difference some more until it get better
plot(diff(diff(ts, 12),1), type='o', main='Second difference')
acf(diff(diff(ts, 12),1), main='Monthly CO2 flask reading')
pacf(diff(diff(ts, 12),1), main='Monthly CO2 flask reading')

#Based on the fact that both the acf and pacf function tail off, we conclude that an arma style model fits best, in this case a sarima model.

## The autocorrlation now seems ok, we will not make our model to complex, so we ## decide on using the selected values. 
```

Now plotting the transformed data we get:
```{r}
ts.transformed <- diff(diff(ts, 12),2)
plot(ts.transformed, type = 'o')
```
Which seems like a stationary process.  

So we decide on using  $\nabla\nabla^{12}$ as our tranformation. 

Which results in a SARIMA model. As for instance:
```{r}
sarima(ts, p=1, d=2, q=1, P=1, Q=1, D=2, S=12)
#test

```
(Coefficient can i.e. be fit using innovations algoritihm. But that might not be the method impletemented in the package).
To find the best choice of parameters we compare AIC and AICC of different models. 

```{r}
optimal_sarima = function(timeseries){
minVal.AIC <- c(10000,1,1,1,1)
minVal.AICC <- c(10000,1,1,1,1)
minVal.BIC <- c(10000,1,1,1,1)
errorAt <- c()
for(p1 in 4:5){
  for(q1 in 1:5){
    for(P1 in 1:5){
      for(Q1 in 1:5){
        mod <- tryCatch(sarima(ts, p=p1, d=2, q=q1, P=P1, D=2, S=12, Q = Q1, no.constant = T, tol = 1e-3),
                 error = function(e) "ERROR")
        if(mod == "ERROR"){
          errorAt <- append(errorAt, c(p1, q1, P1, Q1))
          next
        }
        if(mod$AIC < minVal.AIC[1]){
          minVal.AIC <- c(mod$AIC, p1, q1, P1, Q1)
        }
        if(mod$AICc < minVal.AICC[1]){
          minVal.AICC <- c(mod$AICc, p1, q1, P1, Q1)
        }
        if(mod$BIC < minVal.BIC[1]){
          minVal.BIC <- c(mod$BIC, p1, q1, P1, Q1)
        }
        
      }
    }
  }
}
return(minVal.AICC)
}
# 4 1 5 1 seems to be best with 1.27 AIC and 1.27 AICC 
```

```{r}
mod <- sarima(ts, p=4, d=2, q=1, P=5, Q=1, D=2, S=12)
mod$ttable
```

```{r}
#Confidence intervals
#Since we have a large sample size we can use a normal approximation to calculate the confidence intervals to be the estimate plus/minus 
# their estimate/1.96*their standard deviation
ci = c()
for(i in 1:11){
  upper = mod$ttable[i, 1] + 1.96*mod$ttable[i, 2]
  lower = mod$ttable[i, 1] - 1.96*mod$ttable[i, 2]
  ci = rbind(ci, c(mod$ttable[i, 1], lower, upper))
}
ci = as.data.frame(ci)
names(ci) = c("Estimate", "Lower bound", "Upper bound")
ci

```


```{r}

#Predictions
pred_plot=function(model_fit, original_timeseries, y_label){
  
fore = predict(mod$fit, n.ahead=300)
forecast = append(original_timeseries, fore$pred)
ts.plot(original_timeseries, xlim=c(0,1000), ylim=c(310, 500), ylab=y_label)
U = fore$pred+fore$se; L = fore$pred-fore$se 
xx = c(time(U), rev(time(U))); yy = c(L, rev(U)) 
polygon(xx, yy, border = 8, col = gray(.6, alpha =.2)) 
lines(fore$pred, col=2)
}

pred_plot(mod$fit, ts, 'Monthly CO2')
```

We see that the SARIMA generates a reasonable prediction.

Now let us explore the remaining data.
```{r}
#Monthly in situ

#Plots
ts_monthly_insitu = as.ts(na.omit(monthly_insitu$CO2_filled), deltat=1/12)
plotter(ts_monthly_insitu, 12)
plotter(ts, 12)
#Daily flask and insitu

ts_daily_flask = as.ts(na.omit(daily_flask$CO2), deltat=1/365)
ts_daily_insitu = as.ts(na.omit(daily_insitu$CO2), deltat=1/365)
plot.ts(ts_daily_flask, type='s')
plot.ts(ts_daily_insitu, type='s')

#Insitu lacks outliers
#Differencing and acf
acf2(ts_daily_flask)
acf2(ts_daily_insitu)

#First difference
acf2(diff(ts_daily_flask, 365))
acf2(diff(ts_daily_insitu, 365))


'?'(acf)
#Second difference
acf2(diff(diff(ts_daily_flask, 365)))
acf2(diff(diff(ts_daily_insitu, 365)))


#C13
plotter(as.ts(monthly_c13iso$C13_filled, deltat=1/12), 12)
plotter(as.ts(daily_c13iso$C13, deltat=1/365), 365)

#O18
plotter(as.ts(monthly_o18iso$O18, deltat=1/12), 12)
plotter(as.ts(daily_o18iso$O18, deltat=1/365), 365)
plot(as.ts(monthly_o18iso$O18, deltat=1/12))

#Weekly
plotter(as.ts(weekly_insitu$CO2, deltat=1/52), 52)

#Ten minutes
plotter(as.ts(ten_min_insitu$CO2, deltat=1/525600), 525600)

#Intermittent
plotter(as.ts(intermittent_c13iso$C13, deltat=1/8), 8)



```



```{r}
#Creating function that makes all the necessary plots of statistics and the function
plotter = function(timeseries, first_diff, name){
  plot.ts(timeseries, type='s')
  acf2(timeseries)
  
  #First differencing
  plot.ts(diff(timeseries, first_diff), type='s')
  acf2(diff(timeseries, first_diff))
  
  #Second differencing
  plot.ts(diff(diff(timeseries, first_diff)), type='s')
  acf2(diff(diff(timeseries, first_diff)))
}
```


#Remaining



Plots with the different timeseries' predictions
Discussion
Clean up and prettify things, though probs not really necessary
Save desired plots and give them proper titles


# Discussion
We see that the data look broadly the same, but that in situ data tend to have better looking acf functions. We prefer monthly data over daily data as there are more outliers in the daily data, making it harder to produce a good model.The C13 data and 018 data seem to be mean adjusted in some way, but their acf functions suggested that a two times differencing was appropriate. All the monthly data show broadly similar acf functions after two times differencing, with the only major difference being between flask and in situ data.

We see that models trained on the different kinds of monthly data yield AICC scores and standard errors that are...


'Mention that differencing is better than trend and seasonal element removal can find quote in the book'.

We chose a SARIMA model because...

Drawbacks of this approach are...

We observe that model yields predictions that are reasonable. It becomes less and less certain the further out in time it predicts, which is also reasonable.

Alternative models are...

Weaknesses of chosen model and alternative models.

# Conclusion

We can conclude from our analysis and model that co2 levels will keep increasing into the future at a rate similar to the current rate.

# Appendix

# References

